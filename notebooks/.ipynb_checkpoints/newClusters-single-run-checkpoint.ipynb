{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Results\n",
    "### Single run\n",
    "\n",
    "In this notebook we show the results of the cluster estimations for a given Copacabana run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, vstack\n",
    "from astropy.io.fits import getdata\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the run we take a look into is:\n",
    "\n",
    "run = 'g001-rhod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master file: \n",
      " /data/des61.a/data/johnny/Buzzard/Buzzard_v2.0.0/output/tiles/buzzard_v2.0.0_copa_golden_00001.hdf5\n",
      "/data/des61.a/data/johnny/Buzzard/Buzzard_v2.0.0/output/tiles/buzzard_v2.0.0_copa_golden_00002.hdf5\n",
      "/data/des61.a/data/johnny/Buzzard/Buzzard_v2.0.0/output/tiles/buzzard_v2.0.0_copa_golden_00003.hdf5\n",
      "outdir: /data/des61.a/data/johnny/Buzzard/Buzzard_v2.0.0/output/\n",
      "tile path: /data/des61.a/data/johnny/Buzzard/Buzzard_v2.0.0/output/tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/des.opensciencegrid.org/fnal/anaconda2/envs/des18a/lib/python2.7/site-packages/ipykernel_launcher.py:193: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "vc = viewClusters()\n",
    "vc.load_data(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/des.opensciencegrid.org/fnal/anaconda2/envs/des18a/lib/python2.7/site-packages/ipykernel_launcher.py:193: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "vc.compute_residuals(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5e39a550129e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-f4d17f0ecb4d>\u001b[0m in \u001b[0;36meval_metrics\u001b[0;34m(self, run_name, metric)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mdtypes\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<f8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mscores\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m99.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "vc.eval_metrics(run,'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes      = [(col,'<f8') for col in vc.predictors]\n",
    "scores      = np.full((1,),-99.,dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('Ngals', '<f8'), ('MU', '<f8'), ('R200', '<f8')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., -99., -99.)],\n",
       "      dtype=[('Ngals', '<f8'), ('MU', '<f8'), ('R200', '<f8')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/s1/jesteves/git/ccopa/python/\")\n",
    "\n",
    "from main import copacabana\n",
    "\n",
    "class viewClusters:\n",
    "    def __init__(self):\n",
    "        '/home/s1/jesteves/perl5/bin'\n",
    "        cfg = '/home/s1/jesteves/git/ccopa/config_files/config_buzzard_v2.yaml'\n",
    "        self.copa = copacabana(cfg,dataset='buzzard_v2')\n",
    "\n",
    "        self.models  = defaultdict(dict)\n",
    "        self.metrics = defaultdict(dict)\n",
    "\n",
    "        self.predictors = ['Ngals','MU','R200']\n",
    "        self.regressors = ['Ngals_true','MU_TRUE','R200_true']\n",
    "        self.aux_vars   = ['Ngals_true','MU_TRUE','R200_true','redshift','M200_true']\n",
    "        \n",
    "        self.npredictors = len(self.predictors)\n",
    "        self.nauxialiars = len(self.aux_vars)\n",
    "        \n",
    "        self.metric_funcs = {\"bias\": bias_log_res,\n",
    "                             \"scatter_stdev\": fractional_error_stdev,\n",
    "                             \"scatter_percentile\": fractional_error_percentile,\n",
    "                             \"scatter_nmad\": get_sigmaNMAD,\n",
    "                             \"outlier_frac\": get_outlier_frac}\n",
    "        pass\n",
    "\n",
    "    def load_data(self,run_name):\n",
    "        cat = self.copa.load_copa_out('cluster',run_name)\n",
    "        self.df  = cat.to_pandas()\n",
    "        \n",
    "        self.models[run_name]['predictors'] = np.array(cat[self.predictors])\n",
    "        self.models[run_name]['regressors'] = np.array(cat[self.regressors])\n",
    "        self.models[run_name]['aux_vars']   = np.array(cat[self.aux_vars])\n",
    "        self.compute_residuals(run_name)\n",
    "    \n",
    "    def compute_resiudal_all(self):\n",
    "        runs = self.models.keys()\n",
    "        for run_name in runs:\n",
    "            self.compute_residuals(run_name)\n",
    "            \n",
    "    def compute_residuals(self,run_name):\n",
    "        self.models[run_name]['residual']     = np.full_like(self.models[run_name]['predictors'],-99.)\n",
    "        self.models[run_name]['log_residual'] = np.full_like(self.models[run_name]['predictors'],-99.)\n",
    "\n",
    "        for colx,coly in zip(self.regressors,self.predictors):\n",
    "            x = self.models[run_name]['regressors'][colx]\n",
    "            y = self.models[run_name]['predictors'][coly]\n",
    "            res, log_res = get_frac_residual(x,y)\n",
    "            self.models[run_name]['residual'][coly] = res\n",
    "            self.models[run_name]['log_residual'][coly] = log_res\n",
    "\n",
    "    def make_bins(self, ngals_bins, mu_star_bins, r200_bins, zcls_bins, mass_bins):\n",
    "        mybins             = [ngals_bins, mu_star_bins, r200_bins, zcls_bins, mass_bins]\n",
    "        self.metrics['bins']= dict()\n",
    "        for jj,xbin in zip(self.aux_vars,mybins):\n",
    "            self.metrics['bins'][jj]  = xbin\n",
    "            self.metrics['nbins'][jj] = xbin.size - 1\n",
    "        \n",
    "        runs = list(self.models.keys())\n",
    "        for run_name in runs:\n",
    "            labels,values = self._make_bins(mybins,run_name)\n",
    "            self.models[run_name]['bins_idx'] = labels\n",
    "            self.models[run_name]['bins_val'] = values\n",
    "        \n",
    "    def _make_bins(self,bins,run_name):\n",
    "        labels = np.full_like(self.models[run_name]['aux_vars'],-99.)\n",
    "        values = np.full_like(self.models[run_name]['aux_vars'],-99.)\n",
    "        for xbin,col in zip(bins,self.aux_vars):\n",
    "            x = self.models[run_name]['aux_vars'][col]\n",
    "            keys,xbins = get_bins(x,xbin)\n",
    "            labels[col]= keys\n",
    "            values[col]= xbins\n",
    "        return labels,values\n",
    "\n",
    "    ### compute metrics\n",
    "    def compute_bin_statstics(self,run_name):\n",
    "        ## out: dict('xbins','xmean','nobjs')\n",
    "        out = defaultdict(dict)\n",
    "        self.metrics[run_name] = out\n",
    "        for jj in self.aux_vars:\n",
    "            id_bins = self.models[run_name]['bins_idx'][jj].astype(np.int)    \n",
    "            xs_vals = self.models[run_name]['aux_vars'][jj]\n",
    "            ys_true = self.models[run_name]['predictors']\n",
    "            res     = self.models[run_name]['residual']\n",
    "                \n",
    "            nbins    = self.metrics['nbins'][jj]\n",
    "            xbins    = self.metrics['bins'][jj]\n",
    "            \n",
    "            indices  = np.arange(nbins,dtype=np.int)\n",
    "            xmean    = get_binned_mean(xs_vals,xs_vals,xbins)#0.5*(xbins[1:]+xbins[:-1])\n",
    "            nobjs    = np.histogram(xs_vals,bins=xbins)[0]\n",
    "            \n",
    "            ymean       = np.full_like(ys_true,np.nan)[:nbins]\n",
    "            resmean     = ymean.copy()\n",
    "            \n",
    "            for ii in self.predictors:\n",
    "                ymean[ii]     = get_binned_mean(xs_vals,ys_true[ii],xbins)\n",
    "                resmean[ii]   = get_binned_mean(xs_vals,res[ii],xbins)\n",
    "                \n",
    "            mydict   = {'bins':indices,'xbins':xbins,'xmean':xmean,'ymean':ymean,'res_mean':resmean,\n",
    "                        'nobjs':nobjs}            \n",
    "            self.metrics[run_name][jj] = mydict\n",
    "    \n",
    "    def eval_metrics(self,run_name,metric):\n",
    "        ys_predict = self.models[run_name]['predictors']\n",
    "        ys_true    = self.models[run_name]['regressors']\n",
    "        \n",
    "        dtypes      = [(col,'<f8') for col in self.predictors]\n",
    "        scores      = np.full((1,),-99.,dtype=dtypes)\n",
    "        print(scores.dtype)\n",
    "        for ii in self.predictors:\n",
    "            print(ii)\n",
    "            scores[ii]  = self.metric_funcs[metric](ys_true[ii],ys_predict[ii])\n",
    "    \n",
    "    def eval_bin_all(self):\n",
    "        runs   = self.models.keys()\n",
    "        metrics= self.metric_funcs.keys()\n",
    "        for run_name in runs:\n",
    "            for metric in metrics: self.eval_metrics_bin(run_name, metric)\n",
    "            \n",
    "    def eval_metrics_bin(self, run_name, metric):\n",
    "        #error_message = f\"{run_name} not yet trained\"\n",
    "        #assert run_name in self.models, error_message\n",
    "\n",
    "        ys_predict = self.models[run_name]['predictors']\n",
    "        ys_true    = self.models[run_name]['regressors']\n",
    "        xs_vals    = self.models[run_name]['aux_vars']\n",
    "        \n",
    "        for jj in self.aux_vars:\n",
    "            xbins   = self.metrics[run_name][jj]['xbins']\n",
    "            dtypes      = [(col,'<f8') for col in self.predictors]\n",
    "            scores      = np.full_like(xbins[1:],-99.,dtype=dtypes)\n",
    "            for ii,kk in zip(self.predictors,self.regressors):\n",
    "                scores[ii]  = self.metrics_bin(metric, ys_true[kk],ys_predict[ii], xs_vals[jj], xbins)\n",
    "            self.metrics[run_name][jj][metric] = scores\n",
    "\n",
    "    def metrics_bin(self,metric,ytrue,ypred,xvar,xbins):\n",
    "        error_message = ('{} not recognized! options are: {}'\n",
    "                         ''.format(metric, self.metric_funcs.keys()))\n",
    "        assert metric in self.metric_funcs, error_message\n",
    "        \n",
    "        keys     = get_bins_group_indices(xvar,xbins)\n",
    "        ytrue_bin= group_by(ytrue,keys)#get_bins_group(x,ytrue,xbins)\n",
    "        ypred_bin= group_by(ypred,keys)#get_bins_group(x,ypred,xbins)#[ypred[idx] for idx in keys]\n",
    "        \n",
    "        nbins    = len(xbins)-1\n",
    "        scores   = np.full_like(xbins[:-1],-99.,dtype=np.float64)\n",
    "        \n",
    "        for i,yt,yp in zip(range(nbins),ytrue_bin,ypred_bin):\n",
    "            scores[i] = self.metric_funcs[metric](yt,yp)\n",
    "        return scores\n",
    "\n",
    "def group_by(x,keys):\n",
    "    return [x[idx] for idx in keys]\n",
    "    \n",
    "def get_bins_group_indices(x,bins):\n",
    "    idx  = np.argsort(x)\n",
    "    ## to avoid the boundary condition of the digitize function as xlow <= x < xup\n",
    "    mybins = bins.copy()\n",
    "    mybins[-1] += 0.1\n",
    "    inds = np.digitize(x,mybins)\n",
    "    return np.split(idx, np.unique(inds[idx], return_index=True)[1][1:])\n",
    "    \n",
    "def get_bins_group(x,y,bins):\n",
    "    idx  = np.argsort(x)\n",
    "    ## to avoid the boundary condition of the digitize function as xlow <= x < xup\n",
    "    mybins = bins.copy()\n",
    "    mybins[-1] += 0.1\n",
    "    inds = np.digitize(x,mybins)\n",
    "    return np.split(y[idx], np.unique(inds[idx], return_index=True)[1][1:])\n",
    "    \n",
    "def get_binned_mean(x,y,bins):\n",
    "    mask  = np.logical_not(np.isnan(x)|np.isnan(y))\n",
    "    sum_y = np.histogram(x[mask], bins, weights=y[mask])[0]\n",
    "    nobjs = np.histogram(x[mask], bins)[0]\n",
    "    return sum_y/nobjs\n",
    "    \n",
    "def get_bins(variable,xedges):\n",
    "    nbins   = len(xedges)-1\n",
    "    indices = np.full_like(variable,-99,dtype=np.int)\n",
    "    xbins   = np.full_like(variable,-99,dtype=np.float)\n",
    "\n",
    "    means = (xedges[1:]+xedges[:-1])/2.\n",
    "    for i in range(nbins):\n",
    "        idx = np.where((variable >= xedges[i]) & (variable <= xedges[i + 1]))[0]\n",
    "        xbins[idx]   = means[i]\n",
    "        indices[idx] = i\n",
    "    return indices, xbins\n",
    "\n",
    "def get_log(x):\n",
    "    xlog = np.log10(x)\n",
    "    xlog[np.isinf(xlog)] = -99\n",
    "    xlog[np.isnan(xlog)] = -99\n",
    "    return xlog\n",
    "\n",
    "def get_frac_residual(x,y):\n",
    "    res = y/(x+1e-6)\n",
    "    log_res = get_log(res)\n",
    "    return res,log_res\n",
    "\n",
    "def mad(data, axis=None):\n",
    "    return np.median(np.abs(data - np.median(data)))\n",
    "\n",
    "def median_absolute_dev(x,y):\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    return mad(res[log_res>-99])\n",
    "\n",
    "def bias_log_res(x,y):\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    mask = log_res>-99.\n",
    "    return 1-10**np.median(log_res[mask])\n",
    "\n",
    "def fractional_error_stdev(x, y):\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    score = np.std(res[log_res>-99])\n",
    "    return score\n",
    "\n",
    "def fractional_error_percentile(x, y):\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    mask = log_res>-99.\n",
    "    p16 = np.percentile(res[mask], 16)\n",
    "    p84 = np.percentile(res[mask], 84)\n",
    "    score = 0.5*(p84-p16)\n",
    "    return score\n",
    "\n",
    "def get_sigmaNMAD(x,y):\n",
    "    sigmaNMAD = 1.4*median_absolute_dev(x,y)\n",
    "    return sigmaNMAD\n",
    "\n",
    "def get_outlier_frac(x,y):\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    sigmaNMAD = 1.4*mad(log_res[log_res>-99])\n",
    "    bias      = np.nanmedian(log_res[log_res>-99])\n",
    "    out       = np.where(np.abs((log_res-bias)>=3.*sigmaNMAD))[0]\n",
    "    frac      = 1.*out.size/x.size\n",
    "    return frac\n",
    "\n",
    "def r2_score(x,y):\n",
    "    \"\"\" returns non-aggregate version of r2 score.\n",
    "\n",
    "    based on r2_score() function from sklearn (http://sklearn.org)\n",
    "    \"\"\"\n",
    "    res, log_res = get_frac_residual(x,y)\n",
    "    mask = log_res>-99.\n",
    "    return sklearn.metrics.r2_score(x[mask],y[mask]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
